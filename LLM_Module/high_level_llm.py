#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é«˜å±‚LLM - ä»»åŠ¡è§„åˆ’å™¨
è´Ÿè´£ç†è§£ç”¨æˆ·æ„å›¾ã€ç”Ÿæˆä»»åŠ¡åºåˆ—ã€å¤„ç†ç¯å¢ƒå˜åŒ–æ—¶çš„é‡æ–°è§„åˆ’
"""
import os
import sys
import yaml
import json
from openai import OpenAI
from typing import List, Dict, Any, Optional
from pathlib import Path


class HighLevelLLM:
    """
    é«˜å±‚LLMï¼šä»»åŠ¡è§„åˆ’å™¨

    èŒè´£ï¼š
    1. ç†è§£ç”¨æˆ·è‡ªç„¶è¯­è¨€æŒ‡ä»¤
    2. æ ¹æ® VLM ç¯å¢ƒç†è§£å’Œç”¨æˆ·è¾“å…¥ç”Ÿæˆä»»åŠ¡åºåˆ—
    3. å½“ç¯å¢ƒå˜åŒ–æ—¶é‡æ–°è§„åˆ’
    4. ç®¡ç†ä»»åŠ¡é˜Ÿåˆ—
    """

    def __init__(self,
                 api_key: str,
                 base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1",
                 model: str = "qwen3-32b",
                 prompt_path: str = None,
                 vlm_core: Optional['VLMCore'] = None):
        """
        åˆå§‹åŒ–é«˜å±‚LLM

        Args:
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆæ–‡æœ¬LLMï¼‰
            prompt_path: è§„åˆ’æç¤ºè¯æ–‡ä»¶è·¯å¾„
            vlm_core: VLMæ ¸å¿ƒå®ä¾‹ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä¸ä½¿ç”¨VLMï¼‰
        """
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.prompt_path = prompt_path
        self.vlm_core = vlm_core  # VLM æ ¸å¿ƒå®ä¾‹
        self.prompt_template = self._load_prompt_template()

        if self.vlm_core:
            print(f"[High-Level LLM] VLM åŠŸèƒ½å·²å¯ç”¨", file=sys.stderr)
        else:
            print(f"[High-Level LLM] VLM åŠŸèƒ½æœªå¯ç”¨", file=sys.stderr)

    def _load_prompt_template(self) -> str:
        """ä»YAMLæ–‡ä»¶åŠ è½½è§„åˆ’Promptæ¨¡æ¿"""
        if not self.prompt_path or not os.path.exists(self.prompt_path):
            print("âš ï¸  è­¦å‘Š: Promptæ–‡ä»¶è·¯å¾„æœªæä¾›æˆ–ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å†…ç½®Prompt", file=sys.stderr)
            return self._get_default_prompt()

        try:
            with open(self.prompt_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                return data.get("prompt", "")
        except Exception as e:
            print(f"âŒ é”™è¯¯: åŠ è½½Promptæ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
            return self._get_default_prompt()

    def _get_default_prompt(self) -> str:
        """è·å–é»˜è®¤çš„è§„åˆ’Prompt"""
        return """ä½ æ˜¯ä¸€ä¸ªæœºå™¨äººä»»åŠ¡è§„åˆ’åŠ©æ‰‹ã€‚ä½ çš„èŒè´£æ˜¯å°†ç”¨æˆ·çš„å¤æ‚æŒ‡ä»¤åˆ†è§£ä¸ºç®€å•çš„ã€é¡ºåºæ‰§è¡Œçš„å­ä»»åŠ¡ã€‚

å¯ç”¨æŠ€èƒ½:
{available_skills}

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "tasks": [
    {{"step": 1, "task": "å­ä»»åŠ¡æè¿°1", "type": "åŠ¨ä½œç±»å‹"}},
    {{"step": 2, "task": "å­ä»»åŠ¡æè¿°2", "type": "åŠ¨ä½œç±»å‹"}}
  ],
  "summary": "æ•´ä½“ä»»åŠ¡æ¦‚è¿°"
}}

ç”¨æˆ·è¾“å…¥ï¼š{user_input}

è¯·å°†ä¸Šè¿°æŒ‡ä»¤åˆ†è§£ä¸ºå­ä»»åŠ¡åºåˆ—ã€‚"""

    def plan_tasks(self,
                   user_input: str,
                   available_skills: List[str],
                   env_state: Optional[Dict[str, Any]] = None,
                   image_path: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œç¯å¢ƒçŠ¶æ€ç”Ÿæˆä»»åŠ¡åºåˆ—

        Args:
            user_input: ç”¨æˆ·è‡ªç„¶è¯­è¨€æŒ‡ä»¤
            available_skills: å¯ç”¨æŠ€èƒ½åˆ—è¡¨
            env_state: å½“å‰ç¯å¢ƒçŠ¶æ€ï¼ˆå¯é€‰ï¼‰
            image_path: ç¯å¢ƒå›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºVLMç†è§£ï¼‰

        Returns:
            ä»»åŠ¡åºåˆ—åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"step": 1, "task": "...", "type": "..."}, ...]
        """
        print("\n" + "="*60, file=sys.stderr)
        print("ğŸ§  [é«˜å±‚LLM] ä»»åŠ¡è§„åˆ’ä¸­...", file=sys.stderr)
        print("="*60, file=sys.stderr)

        # ==================== VLM ç¯å¢ƒç†è§£ ====================
        vlm_understanding = ""

        # å¦‚æœæ²¡æœ‰æä¾›å›¾ç‰‡ï¼Œä½¿ç”¨é»˜è®¤å›¾ç‰‡
        use_default_image = False
        if image_path is None and self.vlm_core:
            # ä½¿ç”¨é»˜è®¤å›¾ç‰‡
            image_path = "/home/xcj/work/FinalProject/VLM_Module/assets/red.png"
            use_default_image = True
            print(f"ğŸ–¼ï¸  [é«˜å±‚LLM] ä½¿ç”¨é»˜è®¤å›¾ç‰‡è¿›è¡Œç¯å¢ƒç†è§£: {image_path}", file=sys.stderr)

        # å¦‚æœæœ‰å›¾ç‰‡ï¼ˆç”¨æˆ·æä¾›çš„æˆ–é»˜è®¤çš„ï¼‰ä¸” VLM å·²åˆå§‹åŒ–
        if image_path and self.vlm_core:
            if not use_default_image:
                print(f"ğŸ–¼ï¸  [é«˜å±‚LLM] ä½¿ç”¨ç”¨æˆ·å›¾ç‰‡è¿›è¡Œç¯å¢ƒç†è§£: {image_path}", file=sys.stderr)

            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
            import os
            if not os.path.exists(image_path):
                print(f"âš ï¸  [VLM] å›¾ç‰‡ä¸å­˜åœ¨: {image_path}ï¼Œè·³è¿‡ç¯å¢ƒç†è§£", file=sys.stderr)
            else:
                print(f"ğŸ–¼ï¸  [é«˜å±‚LLM] æ­£åœ¨åˆ†æç¯å¢ƒå›¾åƒ...", file=sys.stderr)
                vlm_result = self.vlm_core.analyze_environment(image_path)

                if vlm_result:
                    # æ˜¾ç¤º VLM çš„åˆ†æç»“æœï¼ˆ200å­—å·¦å³ï¼‰
                    print(f"ğŸ“· [VLM ç¯å¢ƒåˆ†æç»“æœ]\n{vlm_result}\n", file=sys.stderr)
                    vlm_understanding = f"ã€ç¯å¢ƒè§‚å¯Ÿã€‘\n{vlm_result}"
                    print(f"âœ… [é«˜å±‚LLM] VLM ç¯å¢ƒç†è§£å®Œæˆ", file=sys.stderr)
                else:
                    print("âš ï¸  [é«˜å±‚LLM] VLM ç¯å¢ƒç†è§£å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æ–‡æœ¬è§„åˆ’", file=sys.stderr)
        # ==========================================================

        # æ„å»ºprompt
        skills_desc = "\n".join([f"  - {skill}" for skill in available_skills])

        # å‡†å¤‡ç”¨æˆ·è¾“å…¥éƒ¨åˆ†ï¼ˆåŒ…å«VLMç†è§£ï¼‰
        user_input_section = user_input
        if vlm_understanding:
            user_input_section = f"{vlm_understanding}\n\nã€ç”¨æˆ·æŒ‡ä»¤ã€‘\n{user_input}"

        # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å·²ç»åŒ…å«available_skillsï¼ˆå·²ç”±load_dynamic_promptå¡«å……ï¼‰
        if "{available_skills}" in self.prompt_template:
            # è¿˜æœªå¡«å……ï¼Œä½¿ç”¨ä¼ å…¥çš„skills
            prompt = self.prompt_template.format(
                user_input=user_input_section,  # ä½¿ç”¨å¢å¼ºçš„è¾“å…¥
                available_skills=skills_desc
            )
        else:
            # å·²ç»å¡«å……è¿‡äº†ï¼Œåªæ›¿æ¢user_input
            prompt = self.prompt_template.format(
                user_input=user_input_section  # ä½¿ç”¨å¢å¼ºçš„è¾“å…¥
            )

        # æ·»åŠ ç¯å¢ƒçŠ¶æ€ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if env_state:
            prompt += f"\n\nå½“å‰ç¯å¢ƒçŠ¶æ€:\n{json.dumps(env_state, indent=2, ensure_ascii=False)}"

        try:
            # ä½¿ç”¨ç®€åŒ–çš„ promptï¼Œè¦æ±‚åœ¨ JSON ä¸­åŒ…å« reasoning å­—æ®µ
            enhanced_prompt = f"""è¯·å°†ç”¨æˆ·çš„æŒ‡ä»¤åˆ†è§£ä¸ºä»»åŠ¡åºåˆ—ã€‚

è¦æ±‚ï¼š
1. å¿…é¡»åœ¨ JSON ä¸­åŒ…å« "reasoning" å­—æ®µï¼Œè¯¦ç»†è¯´æ˜ä½ çš„åˆ†æè¿‡ç¨‹ï¼ˆ300å­—å·¦å³ï¼‰
2. ç„¶ååˆ—å‡ºå…·ä½“çš„ä»»åŠ¡åºåˆ—

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "reasoning": "ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬éœ€æ±‚åˆ†æã€æŠ€èƒ½é€‰æ‹©ã€å‚æ•°è®¾ç½®ç­‰",
  "tasks": [
    {{"step": 1, "task": "å­ä»»åŠ¡æè¿°", "type": "åŠ¨ä½œç±»å‹"}}
  ],
  "summary": "æ•´ä½“ä»»åŠ¡æ¦‚è¿°"
}}

{prompt}"""

            # ä½¿ç”¨æµå¼è°ƒç”¨
            stream = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœºå™¨äººä»»åŠ¡è§„åˆ’åŠ©æ‰‹ã€‚è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œå¿…é¡»åŒ…å«reasoningå­—æ®µè¯´æ˜ä½ çš„æ€è€ƒè¿‡ç¨‹ã€‚"
                    },
                    {"role": "user", "content": enhanced_prompt}
                ],
                temperature=0.3,
                stream=True
            )

            # æ”¶é›†å“åº”
            response_content = []

            for chunk in stream:
                if chunk.choices:
                    delta = chunk.choices[0].delta
                    if hasattr(delta, 'content') and delta.content:
                        response_content.append(delta.content)

            # è·å–å®Œæ•´å“åº”
            full_text = ''.join(response_content).strip()

            # æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ reasoning å­—æ®µï¼‰
            print(f"\nğŸ’­ [High-Level LLM æ€è€ƒè¿‡ç¨‹]\n", file=sys.stderr)

            try:
                # å°è¯•ç›´æ¥è§£æ JSON
                plan = json.loads(full_text)

                # æ£€æŸ¥æ˜¯å¦æœ‰ reasoning å­—æ®µ
                if 'reasoning' in plan and plan['reasoning']:
                    reasoning = plan['reasoning']
                    # é™åˆ¶æ˜¾ç¤ºé•¿åº¦
                    if len(reasoning) > 300:
                        reasoning = reasoning[:300] + '...'
                    print(f"{reasoning}\n", file=sys.stderr)
                else:
                    print("[æç¤º] æ¨¡å‹æœªåŒ…å« reasoning å­—æ®µï¼Œä¸‹æ¬¡ä¼šæç¤ºæ¨¡å‹æ·»åŠ ", file=sys.stderr)

                # æå–ä»»åŠ¡å’Œæ¦‚è¿°
                tasks = plan.get("tasks", [])
                summary = plan.get("summary", "")

            except json.JSONDecodeError:
                # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æ¸…ç† markdown
                if full_text.startswith("```json"):
                    full_text = full_text.split("```")[1]
                    if full_text.startswith("json"):
                        full_text = full_text[5:]
                elif full_text.startswith("```"):
                    full_text = full_text.split("```")[1]

                full_text = full_text.strip()
                plan = json.loads(full_text)

                tasks = plan.get("tasks", [])
                summary = plan.get("summary", "")

                if 'reasoning' in plan and plan['reasoning']:
                    reasoning = plan['reasoning']
                    if len(reasoning) > 300:
                        reasoning = reasoning[:300] + '...'
                    print(f"{reasoning}\n", file=sys.stderr)

            print(f"{'='*60}\n", file=sys.stderr)

            # æ˜¾ç¤ºä»»åŠ¡åºåˆ—
            print(f"\nâœ… [è§„åˆ’å®Œæˆ] å…±åˆ†è§£ä¸º {len(tasks)} ä¸ªå­ä»»åŠ¡", file=sys.stderr)
            print(f"ğŸ“‹ [ä»»åŠ¡æ¦‚è¿°] {summary}\n", file=sys.stderr)
            print("å­ä»»åŠ¡åºåˆ—ï¼š", file=sys.stderr)
            for task in tasks:
                print(f"  æ­¥éª¤ {task['step']}: {task['task']} ({task['type']})", file=sys.stderr)

            return tasks

        except Exception as e:
            print(f"\nâŒ [è§„åˆ’å¤±è´¥] {e}", file=sys.stderr)
            print(f"[å›é€€] å°†ä½œä¸ºå•ä¸ªä»»åŠ¡å¤„ç†", file=sys.stderr)
            # å›é€€ï¼šå°†ç”¨æˆ·è¾“å…¥ä½œä¸ºå•ä¸ªä»»åŠ¡
            return [{
                "step": 1,
                "task": user_input,
                "type": "ç»¼åˆ"
            }]

    def replan_tasks(self,
                     failed_task: Dict[str, Any],
                     env_state: Dict[str, Any],
                     failure_reason: str,
                     original_user_input: str,
                     available_skills: List[str]) -> List[Dict[str, Any]]:
        """
        ä»»åŠ¡å¤±è´¥æ—¶é‡æ–°è§„åˆ’

        Args:
            failed_task: å¤±è´¥çš„ä»»åŠ¡
            env_state: å½“å‰ç¯å¢ƒçŠ¶æ€
            failure_reason: å¤±è´¥åŸå› 
            original_user_input: åŸå§‹ç”¨æˆ·æŒ‡ä»¤
            available_skills: å¯ç”¨æŠ€èƒ½åˆ—è¡¨

        Returns:
            æ–°çš„ä»»åŠ¡åºåˆ—
        """
        print("\n" + "="*60, file=sys.stderr)
        print("ğŸ”„ [é«˜å±‚LLM] é‡æ–°è§„åˆ’ä¸­...", file=sys.stderr)
        print("="*60, file=sys.stderr)
        print(f"å¤±è´¥ä»»åŠ¡: {failed_task.get('task', 'Unknown')}", file=sys.stderr)
        print(f"å¤±è´¥åŸå› : {failure_reason}", file=sys.stderr)

        # æ„å»ºé‡æ–°è§„åˆ’çš„prompt
        replan_prompt = f"""ä½ æ˜¯ä¸€ä¸ªè‡ªé€‚åº”è§„åˆ’ä¸“å®¶ã€‚å½“ä»»åŠ¡æ‰§è¡Œå¤±è´¥æˆ–ç¯å¢ƒå˜åŒ–æ—¶ï¼Œä½ éœ€è¦é‡æ–°è§„åˆ’ã€‚

åŸå§‹ç”¨æˆ·æŒ‡ä»¤: {original_user_input}

å¤±è´¥çš„ä»»åŠ¡:
- æ­¥éª¤: {failed_task.get('step', 'Unknown')}
- æè¿°: {failed_task.get('task', 'Unknown')}
- ç±»å‹: {failed_task.get('type', 'Unknown')}

å¤±è´¥åŸå› : {failure_reason}

å½“å‰ç¯å¢ƒçŠ¶æ€:
{json.dumps(env_state, indent=2, ensure_ascii=False)}

å¯ç”¨æŠ€èƒ½:
{chr(10).join([f'  - {s}' for s in available_skills])}

é‡æ–°è§„åˆ’ç­–ç•¥:
1. åˆ†æå¤±è´¥åŸå› 
2. è¯„ä¼°å½“å‰ç¯å¢ƒçŠ¶æ€
3. ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ
4. è€ƒè™‘ç”¨æˆ·æ„å›¾çš„ä¿æŒ

å¯èƒ½çš„ç­–ç•¥:
- å°è¯•ä¸åŒçš„æ–¹æ³•å®Œæˆç›¸åŒç›®æ ‡
- è°ƒæ•´ä»»åŠ¡é¡ºåº
- å¢åŠ æ„ŸçŸ¥ä»»åŠ¡è·å–æ›´å¤šä¿¡æ¯
- è¯·æ±‚ç”¨æˆ·æ¾„æ¸…æˆ–å¸®åŠ©ï¼ˆå¦‚æœæ˜¯æœ€åæ‰‹æ®µï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "strategy": "é‡æ–°è§„åˆ’ç­–ç•¥æè¿°",
  "tasks": [
    {{"step": 1, "task": "æ–°ä»»åŠ¡æè¿°", "type": "ä»»åŠ¡ç±»å‹"}},
    {{"step": 2, "task": "æ–°ä»»åŠ¡æè¿°", "type": "ä»»åŠ¡ç±»å‹"}}
  ],
  "explanation": "é‡æ–°è§„åˆ’çš„è§£é‡Š"
}}

è¯·ç”Ÿæˆæ–°çš„ä»»åŠ¡è§„åˆ’:"""

        try:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªè‡ªé€‚åº”è§„åˆ’ä¸“å®¶ã€‚è¾“å‡ºå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"
                    },
                    {"role": "user", "content": replan_prompt}
                ],
                temperature=0.4,  # ç¨é«˜ä¸€ç‚¹çš„æ¸©åº¦ä»¥é¼“åŠ±åˆ›é€ æ€§
                extra_body={"enable_thinking": False}
            )

            response_text = completion.choices[0].message.content.strip()

            # æ¸…ç†markdownä»£ç å—æ ‡è®°
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]

            plan = json.loads(response_text)
            tasks = plan.get("tasks", [])
            strategy = plan.get("strategy", "æœªæä¾›ç­–ç•¥")
            explanation = plan.get("explanation", "")

            print(f"\nâœ… [é‡æ–°è§„åˆ’å®Œæˆ] ç­–ç•¥: {strategy}", file=sys.stderr)
            print(f"ğŸ“ [è§„åˆ’è¯´æ˜] {explanation}\n", file=sys.stderr)
            print(f"æ–°ç”Ÿæˆ {len(tasks)} ä¸ªä»»åŠ¡:", file=sys.stderr)
            for task in tasks:
                print(f"  æ­¥éª¤ {task['step']}: {task['task']} ({task['type']})", file=sys.stderr)

            return tasks

        except Exception as e:
            print(f"\nâŒ [é‡æ–°è§„åˆ’å¤±è´¥] {e}", file=sys.stderr)
            print(f"[å›é€€] è¿”å›ç©ºä»»åŠ¡åˆ—è¡¨", file=sys.stderr)
            return []

    def validate_plan(self, tasks: List[Dict[str, Any]]) -> bool:
        """
        éªŒè¯ç”Ÿæˆçš„ä»»åŠ¡è®¡åˆ’æ˜¯å¦æœ‰æ•ˆ

        Args:
            tasks: ä»»åŠ¡åˆ—è¡¨

        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if not tasks:
            return False

        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        for task in tasks:
            if "step" not in task or "task" not in task:
                return False

        return True
